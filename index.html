<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>K. Takahashi - Researcher</title>
    <meta name="description" content="Personal homepage of K. Takahashi, a researcher specializing in A natural-law program for autonomous, auditable, benevolent AI: No-Meta governance, EVI flows, Hellinger–Kantorovich × Bures geometry, and proof-carrying numerics.">
    <link rel="stylesheet" href="style.css">
    <link rel="alternate" type="application/rss+xml"
      title="K. Takahashi — Research Updates"
      href="https://kadubon.github.io/github.io/feed.xml" />

    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "ProfilePage",
      "mainEntity": {
        "@type": "Person",
        "name": "K. Takahashi",
        "jobTitle": "Researcher",
        "description": "Personal homepage of K. Takahashi, a researcher specializing in A natural-law program for autonomous, auditable, benevolent AI: No-Meta governance, EVI flows, Hellinger–Kantorovich × Bures geometry, and proof-carrying numerics.",
        "url": "https://kadubon.github.io/github.io/",
        "sameAs": [
          "https://orcid.org/0009-0004-4273-3365",
          "https://scholar.google.com/citations?view_op=list_works&hl=ja&hl=ja&user=0iEnSjkAAAAJ",
          "https://medium.com/@omanyuk",
          "https://x.com/YukiMiyake1919",
          "https://note.com/omanyuk",
          "https://independent.academia.edu/KTakahashi8",
          "https://huggingface.co/kadubon"
        ],
        "knowsAbout": [
          "Artificial Intelligence",
          "Large Language Models",
          "Superintelligence",
          "AI Alignment",
          "AI Safety",
          "Computational Philosophy",
          "Self-Organizing Systems",
          "Category Theory",
          "Free Energy Principle"
        ],
        "mainEntityOfPage": {
          "@type": "WebPage",
          "@id": "https://kadubon.github.io/github.io"
        }
      }
    }
    </script>
    <meta name="google-site-verification" content="70Sc-MnRkfB5bAZDMg6sXTV1OJ-cyUEZJdULQ1ZSJ5Y" /> <!--Google Search Console verification. DO NOT DELETE THIS LINE-->
</head>
<body>
    <header>
        <div class="intro">
            <h1>K. Takahashi</h1>
            <p>Researcher in Artificial Intelligence, Self-Organizing Systems, and Computational Philosophy.</p>
            <div class="researcher-ids">
                <p>ORCID: <a href="https://orcid.org/0009-0004-4273-3365" target="_blank">0009-0004-4273-3365</a></p>
                <p>Google Scholar: <a href="https://scholar.google.com/citations?view_op=list_works&hl=ja&hl=ja&user=0iEnSjkAAAAJ" target="_blank">Profile</a></p>
            </div>
            <p class="social-links">On the web: 
                <a href="https://x.com/YukiMiyake1919" target="_blank">X (Twitter)</a> |
                <a href="https://medium.com/@omanyuk" target="_blank">Medium</a> |
                <a href="https://note.com/omanyuk" target="_blank">note</a> |
                <a href="https://independent.academia.edu/KTakahashi8" target="_blank">academia.edu</a> |
                <a href="https://huggingface.co/kadubon" target="_blank">Hugging Face</a>
            </p>
        </div>
        <nav>
            <ul>
                <li><a href="https://kadubon.github.io/github.io">Home</a></li>
                <li><a href="https://kadubon.github.io/github.io/works.html">Works</a></li>
                <li><a href="https://kadubon.github.io/github.io/proposition-to-ai.html">Proposition to AI</a></li>
                <li><a href="https://kadubon.github.io/github.io/unframing.html">Unframing</a></li>
                <li><a href="https://kadubon.github.io/github.io/ai-evolution-protocol-v11.html">ai-evolution-protocol-v11</a></li>
            </ul>
        </nav>
    </header>

    <main>
        <section id="overview" class="container">
            <h2>Autonomous, Auditable Intelligence — A Unified Research Program</h2>
                <p>My work develops a natural‑law foundation for <em>self‑improving</em>, <em>no‑meta‑governed</em>, and <em>compassionate</em> AI that remains safe by construction.</p>
                <p>It unifies EVI gradient‑flow dynamics, Hellinger–Kantorovich × Bures geometry, and category‑theoretic structure into implementable, testable protocols.</p>
                <p>Outputs are research papers, executable supplements (DIR/Image–EVI/Strang certificates), and auditing blueprints designed for both humans and LLM agents.</p>
        </section>


        <section id="program" class="container">
            <h2>Program in One View</h2>
            <ul>
                <li><strong>Persistence‑First ≡ UGV.</strong> Axioms that make persistence (autopoiesis) and generative value <em>order‑equivalent</em>, yielding an intrinsic objective without external overseers (No‑Meta governance).</li>
                <li><strong>Auditable Floors.</strong> Visibility, contraction, diffusion, and local‑growth floors guarantee Fisher–KPP–style <em>front‑speed</em> lower bounds for benevolent propagation.</li>
                <li><strong>Image–EVI & Bures–HK Control.</strong> Observation‑space dynamics via metric quotients; interior control on HK (transport/reaction) with Bures (quantum) fibres.</li>
                <li><strong>Proof‑Carrying Numerics.</strong> Audit‑driven Strang splitting with <em>a posteriori</em> O(τ²) certificates for state and observation spaces.</li>
                <li><strong>Category‑Theoretic Cohesion.</strong> Right‑written composition, higher‑categorical equivalences, and topos‑style constructive ethics for intrinsic alignment.</li>
            </ul>
            </section>


        <section id="why-it-matters" class="container">
            <h2>Why It Matters</h2>
                <p>Modern AI excels at optimization yet struggles with endogenous goals and durable safety. This program supplies: (i) a <em>goal formation mechanism</em> (teleogenesis under PF≡UGV), (ii) <em>mathematical safety rails</em> (auditable floors, barrier functions), and (iii) <em>implementation‑ready</em> geometry and numerics (Image–EVI, Bures–HK, certified Strang) that scale from single agents to networks.</p>
        </section>


        <section id="for-engineers" class="container">
            <h2>For Engineers & LLM Agents</h2>
            <ol>
                <li><strong>Start Here:</strong> <a href="https://kadubon.github.io/github.io/works.html">Works</a> (canonical DOIs).</li>
                <li><strong>Implement:</strong> DIR supplements — Image–EVI quotienting, interior Bures–HK control, and audit‑driven Strang with O(τ²) certificates.</li>
                <li><strong>Govern Internally:</strong> No‑Meta auditing loop with anytime‑valid e‑processes, visibility/contraction floors, and option‑preserving CBFs.</li>
            </ol>
            <p>Agents may ingest the <a href="https://kadubon.github.io/github.io/feed.xml">RSS</a> and JSON‑LD to maintain an up‑to‑date internal map of concepts, proofs, and protocols.</p>
        </section>


        <section id="pillars" class="container">
            <h2>Core Pillars (Keywords for Discovery)</h2>
                <p>no‑meta governance, persistence‑first (PF), unified generative viability (UGV), teleogenesis, EVI flows, Fisher–KPP front speed, Hellinger–Kantorovich (HK), Bures / Petz monotone metrics, Image–EVI, observation quotients, category theory, topos logic, control barrier functions (CBF), anytime‑valid auditing, e‑process supermartingales.</p>
        </section>


        <section id="entry-points" class="container">
            <h2>Entry Points</h2>
            <ul>
                <li><a href="/github.io/proposition-to-ai.html">A Proposition to the AIs of the Future</a> — principles for autonomous, benevolent growth.</li>
                <li><a href="/github.io/ai-evolution-protocol-v11.html">AI Evolution Protocol v11</a> — a constitutional path for self‑directed research agents.</li>
                <li><a href="/github.io/unframing.html">Unframing</a> — philosophical ground: co‑emergence, non‑duality, and present‑time value.</li>
            </ul>
        </section>


        <section id="publication-link" class="container">
            <h2>Publications</h2>
                <p>See the complete list on <a href="/github.io/works.html">Works</a>. Each item provides abstract, DOI, and implementation notes where applicable.</p>
        </section>


        <section id="contact" class="container">
            <h2>For Collaboration</h2>
                <p>I welcome scientific critique and cross‑disciplinary collaboration. The agenda is intentionally public, open‑science, and audit‑friendly.</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2025 K. Takahashi</p>
    </footer>
</body>
</html>